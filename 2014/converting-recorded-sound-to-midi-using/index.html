<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>Converting Recorded Sound to MIDI using Fast Fourier Transforms</title> <meta name="description" content="An Android App named FFT midi converter&nbsp;attempts something quite ambitious - converting any recording into MIDI format. To find out more about MIDI and ..."> <link rel="shortcut icon" type="image/png" href="/favicon.png" > <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://incidentnormal.github.io/2014/converting-recorded-sound-to-midi-using/"> <link rel="alternate" type="application/rss+xml" title="IncidentNormal" href="https://incidentnormal.github.io/feed.xml"> <script src="/assets/js/modernizr.js"></script> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-84671760-1', 'auto'); ga('send', 'pageview'); </script> </head> <body"> <main class="wrapper"> <header class="site-header"> <a href="#navbar" id="menu-burger" class="menu-burger">Menu <span class="nav-icon"></span> <svg x="0px" y="0px" width="54px" height="54px" viewBox="0 0 54 54"> <circle fill="transparent" stroke="#000000" stroke-width="1" cx="27" cy="27" r="25" stroke-dasharray="157 157" stroke-dashoffset="157"></circle> </svg> </a> <div id="navbar" class="navbar"> <div class="navigation-wrapper"> <div class="half-block"> <h1><strong>incident</strong>Normal.<sub>github.io</sub></h1> <h2>Navigation</h2> <nav> <ul class="primary-nav"> <li><a href="/">Home</a></li> <li><a href="/blog">Blog</a></li> <li><a href="/about">About</a></li> <li><a href="https://github.com/IncidentNormal" target="_blank"><i class="icon icon-github"></i> Github</a></li> <li><a href="https://twitter.com" target="_blank"><i class="icon icon-twitter"></i> Twitter</a></li> <li><a href="/feed.xml" target="_blank"><i class="icon icon-feed"></i> RSS</a></li> </ul> </nav> </div> </div> </div> </header> <article class="post" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header intro"> <div class="intro-in"> <h1 class="post-title" itemprop="name headline">Converting Recorded Sound to MIDI using Fast Fourier Transforms</h1> <em><h2 class="post-subtitle" itemprop="name subtitle"></h2></em> <p class="post-meta">[ <time datetime="2014-01-29T07:45:00Z" itemprop="datePublished">Jan 29, 2014</time> ] â€¢ [ <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Duncan Tait</span></span> ]</p> </div> </header> <div class="post-content container" itemprop="articleBody"> <span style="font-family: Trebuchet MS, sans-serif;">An Android App named <a href="https://play.google.com/store/apps/details?id=com.patch9.fftmidi" target="_blank">FFT midi converter</a>&nbsp;attempts something quite ambitious - converting any recording into MIDI format. To find out more about MIDI and the standard it's defined by, see my <a href="http://incidentnormal.blogspot.co.uk/2014/01/pitch-shift-calculations.html" target="_blank">Blog Article on Pitch Shift Calculations</a>. Effectively MIDI is an abstracted representation of music (or sound) formed from discrete tones. To turn the complex audio signal of a live recording into MIDI will always be quite an approximate process - that will deal in assumptions, abstractions and inaccuracies. The App itself runs various band-pass filters over the initial recording to attempt to isolate the frequencies with the largest amplitudes (cutting out as much of the background noise as possible). <br /><br />Once these adaptive noise filters have been run over the recorded sound data, the entire recording is then processed through a Fast Fourier Transform (FFT) algorithm - this will be very familiar to any electrical or Digital Signal Processing (DSP) engineers, but perhaps a bit esoteric to regular users. I'll attempt to explain it briefly:<br /><br />The waveform depicted in Figure 1 at the top is a classic slice-in-time representation of the recorded sound signal (or waveform)'s amplitude. &nbsp;The input sample rate (by default) of the phone's microphone (the phone in this case is a Nexus 5) is 8000 Hz, or 8000 samples per second. The waveform at the top is a snippet in time (it changes in real-time to reflect the waveform currently being recorded - and the tone that it corresponds to is extracted), and it has been calculated to correspond to 179.7Hz by an instantaneous FFT. The FFTs are calculated with a <i>window size</i>&nbsp;of 1024 samples - which means that the entire recording is divided into 1024 sample chunks that are processed using FFTs, in near-real time - and the output simplified waveform is then displayed - which is what can be seen in Figure 1 top half.</span><br /><div><span style="font-family: Trebuchet MS, sans-serif;"><br /></span></div><div><span style="font-family: Trebuchet MS, sans-serif;">The bottom half is effectively a histogram of the magnitude of each frequency component in that 1024 sample block. Each frequency corresponds to a tone. In the case of Figure 1, it can be seen that there is a large peak at 179.7 Hz, so this is then deemed to be the primary frequency (and hence tone) for that 1024 sample segment (there are 8000 samples per second, so in terms of time this tone represents 0.128 seconds). FFTs are used to convert raw signal data (amplitude vs. time) in the <i>Frequency Domain</i>, where it's constituent frequencies can be represented as a histogram, like in the bottom half of Figure 1.&nbsp;</span></div><div><span style="font-family: Trebuchet MS, sans-serif;"><br /></span><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-D1EvggCcVTI/UuiqI3pdBdI/AAAAAAAACiY/XyYxtLAnFYo/s1600/2014-01-29+06.44.14.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><span style="font-family: Trebuchet MS, sans-serif;"><img border="0" src="http://4.bp.blogspot.com/-D1EvggCcVTI/UuiqI3pdBdI/AAAAAAAACiY/XyYxtLAnFYo/s1600/2014-01-29+06.44.14.png" height="640" width="360" /></span></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-family: Trebuchet MS, sans-serif;">Figure 1: FFT Midi Converter Recording Screen</span></td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-G3jIo2k07ew/UuirRfhag-I/AAAAAAAACis/sOciVMh4bqU/s1600/2014-01-29+07.15.09.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><span style="font-family: Trebuchet MS, sans-serif;"><img border="0" src="http://1.bp.blogspot.com/-G3jIo2k07ew/UuirRfhag-I/AAAAAAAACis/sOciVMh4bqU/s1600/2014-01-29+07.15.09.png" height="640" width="360" /></span></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-family: Trebuchet MS, sans-serif;">Figure 2: After recording a clip of sound, it can then be processed into a MIDI format</span></td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-WilMgoHYhFo/UuirRddacrI/AAAAAAAACiw/jwl7886_xOU/s1600/2014-01-29+07.15.18.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><span style="font-family: Trebuchet MS, sans-serif;"><img border="0" src="http://3.bp.blogspot.com/-WilMgoHYhFo/UuirRddacrI/AAAAAAAACiw/jwl7886_xOU/s1600/2014-01-29+07.15.18.png" height="640" width="360" /></span></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><span style="font-family: Trebuchet MS, sans-serif;">Figure 3: This MIDI format can then be played, and if desired - saved.</span></td></tr></tbody></table><span style="font-family: Trebuchet MS, sans-serif;">The MIDI sound file will probably not sound very much like whatever was recorded, as it has no capacity for varying loudness, timbre etc. but if a very simple melody is played on a clean instrument (e.g. piano with low reverb), it will convert it faithfully into the constituent tones (musical notes) that it comprises. Look at Figure 3 - behind the popup player; the FFT histogram shows multiple peaks - and this means multiple tones being played polyphonically.&nbsp;</span></div><div><span style="font-family: Trebuchet MS, sans-serif;"><br /></span></div><div><span style="font-family: Trebuchet MS, sans-serif;">What can the MIDI files be used for? Well, music production in the digital age relies on discrete tones and time intervals, and the MIDI sequence can be directly imported onto an instrument in any decent Music Production Software - thus then reconverting it back into something truly musical with all of the dimensions that make music enjoyable (timbre, loudness, reverb, contour and even spatial location).</span><br /><br /></div> </div> <br> <hr> <p>[site.disqus_shortname]: incidentnormal</p> <p>[page.id]: /2014/converting-recorded-sound-to-midi-using</p> <p>[page.title]: Converting Recorded Sound to MIDI using Fast Fourier Transforms</p> <p>disqus_url: [site.url][post.url]: https://incidentnormal.github.io</p> <hr> <aside id="comments" class="disqus"> <div class="container"> <h3><i class="icon icon-comments-o"></i> Comments</h3> <div id="disqus_thread"></div> <script type="text/javascript"> var disqus_shortname = 'incidentnormal'; var disqus_identifier = '/2014/converting-recorded-sound-to-midi-using'; var disqus_title = 'Converting Recorded Sound to MIDI using Fast Fourier Transforms'; var disqus_url = 'https://incidentnormal.github.io/2014/converting-recorded-sound-to-midi-using/'; /*var disqus_developer = 1;*/ (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); </script> <noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a> </noscript> </div> </aside> </article> <footer class="site-footer"> <div class="container"> <ul class="social"> <li><a href="https://github.com/IncidentNormal" }target="_blank"><i class="icon icon-github"></i></a></li> <li><a href="https://www.linkedin.com/in/duncantait" target="_blank"><i class="icon icon-linkedin"></i></a></li> <li><a href="https://twitter.com" target="_blank"><i class="icon icon-twitter"></i></a></li> </ul> <p> <b>&copy;</b> <small>2016 All rights reserved. Made by <strong><a href="https://incidentnormal.github.io" target="_blank">incidentnormal</a></strong> using <strong><a href="http://jekyllrb.com/" target="_blank">Jekyll</a></strong>.</small> </p> </div> </footer> </main> <script src="/assets/js/jquery-2.1.1.js"></script> <script src="/assets/js/main.js"></script> </body> </html><!-- by incidentnormal -->